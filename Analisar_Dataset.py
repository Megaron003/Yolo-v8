from ultralytics import YOLO
import os
import yaml
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

def analisar_dataset_completo():
    """Analisa TODOS os splits - Vers√£o Corrigida"""
    
    base_path = r'C:/Users/GuilhermeBragadoVale/Downloads/axial MRI.v2-release.yolov8'
    
    print("üîç ANALISANDO DATASET COMPLETO (TODOS OS SPLITS)")
    print("="*60)
    
    contador_geral = Counter()
    estatisticas = {}
    
    for split in ['train', 'valid', 'test']:
        labels_path = os.path.join(base_path, split, 'labels')
        images_path = os.path.join(base_path, split, 'images')
        
        print(f"\nüìÅ {split.upper()}:")
        
        # Verificar se pastas existem
        if not os.path.exists(labels_path):
            print(f"   ‚ùå Pasta labels n√£o encontrada: {labels_path}")
            continue
        if not os.path.exists(images_path):
            print(f"   ‚ùå Pasta images n√£o encontrada: {images_path}")
            continue
        
        # Contar arquivos
        imagens = [f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        labels = [f for f in os.listdir(labels_path) if f.endswith('.txt')]
        
        print(f"   üñº Imagens: {len(imagens)}")
        print(f"   üìù Labels: {len(labels)}")
        
        # Verificar correspond√™ncia
        imagens_sem_ext = {os.path.splitext(f)[0] for f in imagens}
        labels_sem_ext = {os.path.splitext(f)[0] for f in labels}
        
        sem_correspondencia = imagens_sem_ext - labels_sem_ext
        if sem_correspondencia:
            print(f"   ‚ö†Ô∏è  Imagens sem labels: {len(sem_correspondencia)}")
        
        # Analisar distribui√ß√£o de classes
        contador_split = Counter()
        total_anotacoes_split = 0
        
        for label_file in labels:
            try:
                with open(os.path.join(labels_path, label_file), 'r') as f:
                    for line in f:
                        if line.strip():
                            class_id = int(line.split()[0])
                            contador_split[class_id] += 1
                            contador_geral[class_id] += 1
                            total_anotacoes_split += 1
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erro em {label_file}: {e}")
                continue
        
        estatisticas[split] = {
            'imagens': len(imagens),
            'labels': len(labels),
            'distribuicao': dict(contador_split),
            'total_anotacoes': total_anotacoes_split
        }
        
        if contador_split:
            print(f"   üéØ Distribui√ß√£o de classes:")
            for class_id, count in sorted(contador_split.items()):
                percentual = (count / total_anotacoes_split) * 100 if total_anotacoes_split > 0 else 0
                print(f"      Classe {class_id}: {count} anota√ß√µes ({percentual:.1f}%)")
    
    # Estat√≠sticas gerais
    print("\n" + "="*60)
    print("üìä ESTAT√çSTICAS GERAIS:")
    print("="*60)
    
    total_imagens = sum(estatisticas[split]['imagens'] for split in estatisticas)
    total_anotacoes = sum(estatisticas[split]['total_anotacoes'] for split in estatisticas)
    
    print(f"üìà TOTAIS:")
    print(f"   üñº Imagens: {total_imagens}")
    print(f"   üìù Anota√ß√µes: {total_anotacoes}")
    print(f"   üéØ Classes detectadas: {len(contador_geral)}")
    
    if contador_geral:
        print(f"\nüéØ DISTRIBUI√á√ÉO GERAL:")
        for class_id, count in sorted(contador_geral.items()):
            percentual = (count / total_anotacoes) * 100
            print(f"   Classe {class_id}: {count} anota√ß√µes ({percentual:.1f}%)")
    
    return estatisticas, contador_geral

def criar_data_yaml_inteligente(contador_geral):
    """Cria data.yaml baseado na an√°lise completa"""
    
    print("\nüìù CRIANDO data.yaml INTELIGENTE...")
    
    base_path = r'C:\Users\GuilhermeBragadoVale\Downloads\axial MRI.v2-release.yolov8'
    
    data_config = {
        'path': base_path,
        'train': 'train',
        'val': 'valid',
        'test': 'test',
        'names': {class_id: f'estrutura_{class_id}' for class_id in sorted(contador_geral.keys())},
        'nc': len(contador_geral)
    }
    
    with open('data.yaml', 'w') as f:
        yaml.dump(data_config, f, default_flow_style=False)
    
    print("‚úÖ data.yaml CRIADO!")
    print(f"üéØ Classes configuradas: {list(sorted(contador_geral.keys()))}")
    
    return 'data.yaml'

def treinar_modelo_otimizado():
    """Treinamento com configura√ß√£o otimizada"""
    
    print("\nüöÄ INICIANDO TREINAMENTO OTIMIZADO")
    print("="*50)
    
    # 1. An√°lise completa do dataset
    estatisticas, contador_geral = analisar_dataset_completo()
    
    if not contador_geral:
        print("‚ùå Nenhuma classe detectada!")
        return None, None
    
    # 2. Criar data.yaml
    data_yaml = criar_data_yaml_inteligente(contador_geral)
    
    # 3. Configura√ß√£o baseada na an√°lise
    num_classes = len(contador_geral)
    
    config_treinamento = {
        'data': data_yaml,
        'epochs': 100,
        'imgsz': 640,
        'batch': 8,
        'device': 'cpu',
        'patience': 20,
        'project': 'runs/detect',
        'name': 'treinamento_otimizado',
        'verbose': True,
        'save': True,
        
        # Configura√ß√µes otimizadas
        'cls': 0.7,
        'lr0': 0.001,
        'weight_decay': 0.001,
        'optimizer': 'AdamW',
        
        # Data augmentation
        'hsv_h': 0.015,
        'hsv_s': 0.7,
        'hsv_v': 0.4,
        'fliplr': 0.5,
    }
    
    # Ajustes para desbalanceamento
    if num_classes > 1:
        max_count = max(contador_geral.values())
        min_count = min(contador_geral.values())
        
        if max_count / min_count > 3:
            print("üéØ Aplicando configura√ß√£o anti-desbalanceamento...")
            config_treinamento.update({
                'cls': 0.8,
                'lr0': 0.0005,
            })
    
    # 4. Treinar
    try:
        print("üì¶ Carregando modelo YOLOv8...")
        model = YOLO('yolov8n.pt')
        
        print("üî• Iniciando treinamento...")
        results = model.train(**config_treinamento)
        
        print("‚úÖ Treinamento conclu√≠do!")
        return model, results
        
    except Exception as e:
        print(f"‚ùå Erro no treinamento: {e}")
        return None, None

def gerar_analises_completas():
    """Gera an√°lises completas: matriz de confus√£o, curvas, etc."""
    
    print("\nüìä GERANDO AN√ÅLISES COMPLETAS DO MODELO")
    print("="*50)
    
    model_path = 'runs/detect/treinamento_otimizado/weights/best.pt'
    
    if not os.path.exists(model_path):
        print(f"‚ùå Modelo n√£o encontrado: {model_path}")
        return None
    
    model = YOLO(model_path)
    
    # 1. Matriz de Confus√£o
    print("\nüéØ GERANDO MATRIZ DE CONFUS√ÉO...")
    try:
        # For√ßar a gera√ß√£o da matriz de confus√£o
        results_dir = 'runs/detect/treinamento_otimizado'
        confusion_matrix_path = os.path.join(results_dir, 'confusion_matrix.png')
        
        # Validar para gerar m√©tricas
        metrics = model.val(split='test')
        
        print("‚úÖ Matriz de Confus√£o e m√©tricas geradas!")
        
        # An√°lise detalhada das m√©tricas
        print("\nüìà AN√ÅLISE DETALHADA DAS M√âTRICAS:")
        print("-" * 40)
        
        if hasattr(metrics, 'box'):
            print(f"üéØ mAP@50-95: {metrics.box.map:.4f}")
            print(f"üéØ mAP@50: {metrics.box.map50:.4f}")
            print(f"üéØ mAP@75: {metrics.box.map75:.4f}")
            
            # Precis√£o por classe
            if hasattr(metrics.box, 'p') and metrics.box.p is not None:
                if hasattr(metrics.box.p, '__iter__'):
                    print(f"\nüéØ PRECIS√ÉO POR CLASSE:")
                    for i, prec in enumerate(metrics.box.p):
                        print(f"   Classe {i}: {prec:.4f}")
                    print(f"   M√©dia: {np.mean(metrics.box.p):.4f}")
            
            # Recall por classe
            if hasattr(metrics.box, 'r') and metrics.box.r is not None:
                if hasattr(metrics.box.r, '__iter__'):
                    print(f"\nüéØ RECALL POR CLASSE:")
                    for i, rec in enumerate(metrics.box.r):
                        print(f"   Classe {i}: {rec:.4f}")
                    print(f"   M√©dia: {np.mean(metrics.box.r):.4f}")
        
        return metrics
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao gerar matriz de confus√£o: {e}")
        return None

def analisar_curvas_aprendizado():
    """Analisa as curvas de aprendizado do treinamento"""
    
    print("\nüìà ANALISANDO CURVAS DE APRENDIZADO")
    print("="*50)
    
    results_dir = 'runs/detect/treinamento_otimizado'
    results_file = os.path.join(results_dir, 'results.csv')
    
    if not os.path.exists(results_file):
        print("‚ùå Arquivo de resultados n√£o encontrado")
        return
    
    try:
        # Ler resultados do treinamento
        import pandas as pd
        results_df = pd.read_csv(results_file)
        
        print("üìä ESTAT√çSTICAS DO TREINAMENTO:")
        print("-" * 30)
        
        # M√©tricas finais
        ultima_linha = results_df.iloc[-1]
        
        print(f"‚úÖ √âpocas treinadas: {len(results_df)}")
        print(f"‚úÖ Loss de caixa final: {ultima_linha.get('train/box_loss', 'N/A'):.4f}")
        print(f"‚úÖ Loss de classe final: {ultima_linha.get('train/cls_loss', 'N/A'):.4f}")
        print(f"‚úÖ Loss total final: {ultima_linha.get('train/loss', 'N/A'):.4f}")
        print(f"‚úÖ mAP@50 final: {ultima_linha.get('metrics/mAP50(B)', 'N/A'):.4f}")
        
        # An√°lise de converg√™ncia
        if len(results_df) > 10:
            primeiras_epocas = results_df['metrics/mAP50(B)'].head(10).mean()
            ultimas_epocas = results_df['metrics/mAP50(B)'].tail(10).mean()
            melhoria = ultimas_epocas - primeiras_epocas
            
            print(f"\nüìà AN√ÅLISE DE CONVERG√äNCIA:")
            print(f"   mAP@50 primeiras 10 √©pocas: {primeiras_epocas:.4f}")
            print(f"   mAP@50 √∫ltimas 10 √©pocas: {ultimas_epocas:.4f}")
            print(f"   Melhoria: {melhoria:.4f}")
            
            if melhoria < 0.01:
                print("   üí° Modelo pode ter convergido cedo")
            elif melhoria > 0.05:
                print("   üí° Modelo ainda estava melhorando")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao analisar curvas: {e}")

def gerar_relatorio_desempenho():
    """Gera relat√≥rio completo de desempenho"""
    
    print("\nüìã GERANDO RELAT√ìRIO COMPLETO DE DESEMPENHO")
    print("="*60)
    
    model_path = 'runs/detect/treinamento_otimizado/weights/best.pt'
    
    if not os.path.exists(model_path):
        print("‚ùå Modelo n√£o encontrado")
        return
    
    model = YOLO(model_path)
    
    # Validar em todos os splits
    print("\nüéØ DESEMPENHO POR SPLIT:")
    print("-" * 30)
    
    splits = ['train', 'val', 'test']
    desempenho = {}
    
    for split in splits:
        try:
            if split == 'train':
                # Para train, usar uma amostra para n√£o demorar muito
                metrics = model.val(split='val')  # Usar val como proxy
            else:
                metrics = model.val(split=split)
            
            if hasattr(metrics, 'box'):
                desempenho[split] = {
                    'map50': metrics.box.map50,
                    'map': metrics.box.map
                }
                print(f"üìÅ {split.upper()}:")
                print(f"   mAP@50: {metrics.box.map50:.4f}")
                print(f"   mAP@50-95: {metrics.box.map:.4f}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao validar {split}: {e}")
    
    # An√°lise comparativa
    if 'train' in desempenho and 'val' in desempenho:
        gap = desempenho['train']['map50'] - desempenho['val']['map50']
        print(f"\nüìä AN√ÅLISE DE GAP TREINO/VALIDA√á√ÉO:")
        print(f"   Gap mAP@50: {gap:.4f}")
        
        if gap > 0.1:
            print("   ‚ö†Ô∏è  Poss√≠vel overfitting (gap muito alto)")
        elif gap < 0.02:
            print("   ‚úÖ Boa generaliza√ß√£o (gap pequeno)")
        else:
            print("   ‚ö†Ô∏è  Gap moderado")

def avaliar_modelo_completo():
    """Avalia√ß√£o completa do modelo - AGORA COM AN√ÅLISES"""
    
    print("\nüìä INICIANDO AVALIA√á√ÉO COMPLETA COM AN√ÅLISES")
    print("="*60)
    
    model_path = 'runs/detect/treinamento_otimizado/weights/best.pt'
    
    if not os.path.exists(model_path):
        print(f"‚ùå Modelo n√£o encontrado: {model_path}")
        return None
    
    model = YOLO(model_path)
    
    # 1. M√©tricas b√°sicas
    print("\nüéØ M√âTRICAS B√ÅSICAS DE VALIDA√á√ÉO")
    print("-" * 40)
    
    metrics = model.val()
    
    if hasattr(metrics, 'box'):
        print(f"üìà mAP@50-95: {getattr(metrics.box, 'map', 0):.4f}")
        print(f"üìà mAP@50: {getattr(metrics.box, 'map50', 0):.4f}")
        print(f"üìà mAP@75: {getattr(metrics.box, 'map75', 0):.4f}")
        
        # Precis√£o e Recall (com tratamento seguro)
        if hasattr(metrics.box, 'p') and metrics.box.p is not None:
            if hasattr(metrics.box.p, 'mean'):
                print(f"üéØ Precis√£o m√©dia: {metrics.box.p.mean():.4f}")
            elif hasattr(metrics.box.p, '__iter__'):
                print(f"üéØ Precis√£o m√©dia: {np.mean(metrics.box.p):.4f}")
                
        if hasattr(metrics.box, 'r') and metrics.box.r is not None:
            if hasattr(metrics.box.r, 'mean'):
                print(f"üéØ Recall m√©dio: {metrics.box.r.mean():.4f}")
            elif hasattr(metrics.box.r, '__iter__'):
                print(f"üéØ Recall m√©dio: {np.mean(metrics.box.r):.4f}")
    
    # 2. An√°lises avan√ßadas
    gerar_analises_completas()
    analisar_curvas_aprendizado()
    gerar_relatorio_desempenho()
    
    return metrics

def fazer_predicoes_avancadas():
    """Faz predi√ß√µes com an√°lise detalhada"""
    
    model_path = 'runs/detect/treinamento_otimizado/weights/best.pt'
    
    if not os.path.exists(model_path):
        print(f"‚ùå Modelo n√£o encontrado: {model_path}")
        return None
    
    model = YOLO(model_path)
    
    test_path = r'C:\Users\GuilhermeBragadoVale\Downloads\axial MRI.v2-release.yolov8\test\images'
    
    print(f"\nüéØ FAZENDO PREDI√á√ïES EM: {test_path}")
    
    results = model.predict(
        source=test_path,
        save=True,
        conf=0.5,
        iou=0.5,
        show_labels=True,
        show_conf=True,
        line_width=2
    )
    
    # Estat√≠sticas das predi√ß√µes
    total_deteccoes = 0
    deteccoes_por_classe = Counter()
    confiancas_por_classe = {}
    
    for result in results:
        if result.boxes is not None:
            total_deteccoes += len(result.boxes)
            for i, cls in enumerate(result.boxes.cls):
                classe = int(cls)
                deteccoes_por_classe[classe] += 1
                
                # Coletar confian√ßas
                if classe not in confiancas_por_classe:
                    confiancas_por_classe[classe] = []
                if hasattr(result.boxes, 'conf'):
                    confiancas_por_classe[classe].append(float(result.boxes.conf[i]))
    
    print(f"\nüìä ESTAT√çSTICAS DAS PREDI√á√ïES:")
    print(f"   üìà Total de detec√ß√µes: {total_deteccoes}")
    print(f"   üìà Total de imagens processadas: {len(results)}")
    print(f"   üéØ Detec√ß√µes por classe:")
    for classe, count in sorted(deteccoes_por_classe.items()):
        conf_media = np.mean(confiancas_por_classe.get(classe, [0]))
        print(f"      Classe {classe}: {count} detec√ß√µes (conf: {conf_media:.3f})")
    
    print(f"\n‚úÖ Predi√ß√µes salvas em: runs/detect/treinamento_otimizado/predict/")
    return results

# üéØ PROGRAMA PRINCIPAL
if __name__ == "__main__":
    print("üéâ SISTEMA DE TREINAMENTO YOLOv8 - VERS√ÉO COMPLETA COM AN√ÅLISES")
    print("="*70)
    
    # Treinar (MANTIDO EXATAMENTE IGUAL)
    modelo, resultados = treinar_modelo_otimizado()
    
    if modelo is not None:
        # Avaliar (AGORA COM AN√ÅLISES COMPLETAS)
        metricas = avaliar_modelo_completo()
        
        # Fazer predi√ß√µes
        predicoes = fazer_predicoes_avancadas()
        
        print("\n" + "="*70)
        print("üéâ PROCESSO COMPLETO CONCLU√çDO!")
        print("üìç Resultados em: runs/detect/treinamento_otimizado/")
        print("üìä An√°lises dispon√≠veis:")
        print("   ‚úÖ Matriz de Confus√£o")
        print("   ‚úÖ Curvas de Aprendizado") 
        print("   ‚úÖ M√©tricas por Classe")
        print("   ‚úÖ Relat√≥rio de Desempenho")
        print("   ‚úÖ Estat√≠sticas de Predi√ß√µes")
    else:
        print("\n‚ùå Processo interrompido devido a erros")